# https://taskfile.dev

version: '3'

vars:
  GENERATED_BENCHMARK_PATH: ./tasks_output/generated_benchmarks

  DEPSYNT_RESULTS_PATH: ./tasks_output/depsynt
  SYNTHESIS_TIMEOUT: 180m
  BENCHMARKS_FAMALIES: "tsl_smart_home_jarvis/extracted-benchmarks,tsl_paper,mux,ltl2dpa,shift"

  FIND_DEPENDENCIES_PATH: ./tasks_output/find_deps
  FIND_DEPENDENCIES_SUMMARY: ./tasks_output/find_deps.csv
  FIND_DEPENDENCIES_TIMEOUT: 60m

tasks:
  # Synthesis
  depsynt:
    cmds:
      - mkdir -p {{.DEPSYNT_RESULTS_PATH}}
      - rm -f {{.DEPSYNT_RESULTS_PATH}}/*
      - rm -f ./submit_depsynt
      - ./scripts/slurm_task_gen.py --task=depsynt --timeout={{.SYNTHESIS_TIMEOUT}} --benchmarks-path={{.GENERATED_BENCHMARK_PATH}}/text --output-path={{.DEPSYNT_RESULTS_PATH}} --families="{{.BENCHMARKS_FAMALIES}}" > submit_depsynt
      - sbatch submit_depsynt

  depsynt_clean_skipped:
    cmds:
      - ./scripts/remove_skipped_synt.sh {{.DEPSYNT_RESULTS_PATH}}

  # Find Dependencies
  find_dependencies:
    cmds:
      - mkdir -p {{.FIND_DEPENDENCIES_PATH}}
      - rm -f {{.FIND_DEPENDENCIES_PATH}}/*
      - rm -f ./submit_find_deps
      - ./scripts/slurm_task_gen.py --task=find_deps --timeout={{.FIND_DEPENDENCIES_TIMEOUT}} --benchmarks-path={{.GENERATED_BENCHMARK_PATH}}/text --output-path={{.FIND_DEPENDENCIES_PATH}} > submit_find_deps
      - sbatch submit_find_deps

  find_dependencies_summary:
    - rm -f {{.FIND_DEPENDENCIES_SUMMARY}}
    - ./scripts/find_deps_summarizer.py --find-deps-result-path={{.FIND_DEPENDENCIES_PATH}} --benchmarks-path={{.GENERATED_BENCHMARK_PATH}}/text --summary-output={{.FIND_DEPENDENCIES_SUMMARY}}

  # Generate benchmarks
  generate_benchmarks:
    cmds:
      - task: generate_benchmarks_clean
      - task: generate_benchmarks_tlsf
      - task: generate_benchmarks_text

  generate_benchmarks_tlsf:
    internal: true
    cmds:
      - mkdir -p {{.GENERATED_BENCHMARK_PATH}}/tlsf
      - ./scripts/benchmarks/tlsf/selectBenchmarks.py ./scripts/benchmarks/tlsf {{.GENERATED_BENCHMARK_PATH}}/tlsf --savestruct
  generate_benchmarks_clean:
    internal: true
    cmds:
      - rm -rf {{.GENERATED_BENCHMARK_PATH}}
      - mkdir -p {{.GENERATED_BENCHMARK_PATH}}
  generate_benchmarks_text:
    internal: true
    deps: [generate_benchmarks_tlsf]
    cmds:
      - rm -rf {{.GENERATED_BENCHMARK_PATH}}/text
      - mkdir -p {{.GENERATED_BENCHMARK_PATH}}/text
      - ./scripts/tlsf_to_text.py {{.GENERATED_BENCHMARK_PATH}}/tlsf {{.GENERATED_BENCHMARK_PATH}}/text
